{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2134c3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Required Libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torch import nn\n",
    "import pytesseract\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "accf6032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted file saved to: C:\\Users\\chara\\Downloads\\Assignment\\Licplatesdetection_train1_sorted_annotations.csv\n"
     ]
    }
   ],
   "source": [
    "#train1_annotations_preprocess\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Excel/CSV file\n",
    "file_path = r\"C:\\Users\\chara\\Downloads\\Assignment\\Licplatesdetection_train1_annotations.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Extract numerical parts from 'img_id' for sorting\n",
    "data['numeric_id'] = data['img_id'].str.extract('(\\d+)')[0].astype(int)\n",
    "\n",
    "# Sort the DataFrame by the numeric values\n",
    "data_sorted = data.sort_values(by='numeric_id').drop(columns=['numeric_id'])\n",
    "\n",
    "# Save the sorted DataFrame to a new file\n",
    "sorted_file_path = r\"C:\\Users\\chara\\Downloads\\Assignment\\Licplatesdetection_train1_sorted_annotations.csv\"\n",
    "data_sorted.to_csv(sorted_file_path, index=False)\n",
    "\n",
    "print(f\"Sorted file saved to: {sorted_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "56234952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing numbers: []\n"
     ]
    }
   ],
   "source": [
    "#train1_annotation_preprocess\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Excel/CSV file\n",
    "file_path = r\"C:\\Users\\chara\\Downloads\\Assignment\\Licplatesdetection_train1_sorted_annotations.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Extract numeric parts from 'img_id'\n",
    "data['numeric_id'] = data['img_id'].str.extract('(\\d+)')[0].astype(int)\n",
    "\n",
    "# Find the range of numbers\n",
    "min_id = data['numeric_id'].min()\n",
    "max_id = data['numeric_id'].max()\n",
    "\n",
    "# Find missing numbers\n",
    "full_range = set(range(min_id, max_id + 1))\n",
    "present_numbers = set(data['numeric_id'])\n",
    "missing_numbers = sorted(full_range - present_numbers)\n",
    "\n",
    "print(f\"Missing numbers: {missing_numbers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "24761ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted file saved to: C:\\Users\\chara\\Downloads\\Assignment\\Licplatesdetection_train2_sorted_annotations.csv\n"
     ]
    }
   ],
   "source": [
    "#train2_annotation_preprocess\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Excel/CSV file\n",
    "file_path =  r\"C:\\Users\\chara\\Downloads\\Assignment\\Licplatesrecognition_train2_annotations.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Extract numerical parts from 'img_id' for sorting\n",
    "data['numeric_id'] = data['img_id'].str.extract('(\\d+)')[0].astype(int)\n",
    "\n",
    "# Sort the DataFrame by the numeric values\n",
    "data_sorted = data.sort_values(by='numeric_id').drop(columns=['numeric_id'])\n",
    "\n",
    "# Save the sorted DataFrame to a new file\n",
    "sorted_file_path = r\"C:\\Users\\chara\\Downloads\\Assignment\\Licplatesdetection_train2_sorted_annotations.csv\"\n",
    "data_sorted.to_csv(sorted_file_path, index=False)\n",
    "\n",
    "print(f\"Sorted file saved to: {sorted_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "48b58056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing numbers: [15, 269, 383, 420, 439, 467, 538, 556, 568, 734, 909]\n"
     ]
    }
   ],
   "source": [
    "#train2_annotation_preprocess\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Excel/CSV file\n",
    "file_path = r\"C:\\Users\\chara\\Downloads\\Assignment\\Licplatesdetection_train2_sorted_annotations.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Extract numeric parts from 'img_id'\n",
    "data['numeric_id'] = data['img_id'].str.extract('(\\d+)')[0].astype(int)\n",
    "\n",
    "# Find the range of numbers\n",
    "min_id = data['numeric_id'].min()\n",
    "max_id = data['numeric_id'].max()\n",
    "\n",
    "# Find missing numbers\n",
    "full_range = set(range(min_id, max_id + 1))\n",
    "present_numbers = set(data['numeric_id'])\n",
    "missing_numbers = sorted(full_range - present_numbers)\n",
    "\n",
    "print(f\"Missing numbers: {missing_numbers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4ce30734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated file saved as: C:\\Users\\chara\\Downloads\\Assignment\\Licplatesdetection_train2_sorted_annotations_updated.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = r\"C:\\Users\\chara\\Downloads\\Assignment\\Licplatesdetection_train2_sorted_annotations.csv\"  # Replace with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Rename the img_id column to sequential numbers from 1 to maximum\n",
    "df['img_id'] = [f\"{i+1}.jpg\" for i in range(len(df))]\n",
    "\n",
    "# Save the updated dataframe to a new CSV file\n",
    "updated_file_path = r\"C:\\Users\\chara\\Downloads\\Assignment\\Licplatesdetection_train2_sorted_annotations_updated.csv\"  # Replace with desired file path\n",
    "df.to_csv(updated_file_path, index=False)\n",
    "\n",
    "print(f\"Updated file saved as: {updated_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "270cdc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images sorted from min to max and copied to: C:\\Users\\chara\\Downloads\\Assignment\\Licplatesdetection_train1_sorted\n"
     ]
    }
   ],
   "source": [
    "#train_preprocessing1\n",
    "\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Path to the original folder containing images\n",
    "image_folder = r\"C:\\Users\\chara\\Downloads\\Assignment\\Licplatesdetection_train1\" \n",
    "\n",
    "# Path to the new folder for sorted images\n",
    "sorted_folder = r\"C:\\Users\\chara\\Downloads\\Assignment\\Licplatesdetection_train1_sorted\"\n",
    "\n",
    "# Step 1: Create the sorted folder if it doesn't exist\n",
    "os.makedirs(sorted_folder, exist_ok=True)\n",
    "\n",
    "# Step 2: List all files in the directory\n",
    "image_files = os.listdir(image_folder)\n",
    "\n",
    "# Step 3: Filter only valid image files (optional, based on your folder's contents)\n",
    "image_files = [f for f in image_files if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "# Step 4: Extract numeric parts of file names and sort them\n",
    "def extract_numeric(file_name):\n",
    "    \"\"\"Extracts numeric value from file name.\"\"\"\n",
    "    base_name = os.path.splitext(file_name)[0]\n",
    "    try:\n",
    "        return int(base_name)\n",
    "    except ValueError:\n",
    "        return float('inf')  # Push non-numeric names to the end if any\n",
    "\n",
    "sorted_files = sorted(image_files, key=extract_numeric)\n",
    "\n",
    "# Step 5: Copy files to the new folder in ascending order\n",
    "for idx, file_name in enumerate(sorted_files, start=1):\n",
    "    old_path = os.path.join(image_folder, file_name)\n",
    "    new_name = f\"{idx:03d}{os.path.splitext(file_name)[1]}\"  # Rename to 001.jpg, 002.jpg, etc.\n",
    "    new_path = os.path.join(sorted_folder, new_name)\n",
    "    shutil.copy2(old_path, new_path)\n",
    "\n",
    "print(f\"Images sorted from min to max and copied to: {sorted_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3adc9b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images found: 900\n",
      "Range of numbers: 1 to 900\n",
      "Missing numbers: None\n"
     ]
    }
   ],
   "source": [
    "#train_preprocessing1\n",
    "\n",
    "import os\n",
    "\n",
    "# Path to the folder containing images\n",
    "image_folder = r\"C:\\Users\\chara\\Downloads\\Assignment\\Licplatesdetection_train1_sorted\"\n",
    "\n",
    "# Step 1: List all files in the directory\n",
    "image_files = os.listdir(image_folder)\n",
    "\n",
    "# Step 2: Filter only valid image files\n",
    "image_files = [f for f in image_files if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "# Step 3: Extract numeric parts of file names\n",
    "def extract_numeric(file_name):\n",
    "    \"\"\"Extracts numeric value from file name.\"\"\"\n",
    "    base_name = os.path.splitext(file_name)[0]\n",
    "    try:\n",
    "        return int(base_name)\n",
    "    except ValueError:\n",
    "        return None  # Ignore files without numeric names\n",
    "\n",
    "image_numbers = [extract_numeric(f) for f in image_files]\n",
    "image_numbers = [num for num in image_numbers if num is not None]  # Remove None values\n",
    "\n",
    "# Step 4: Find missing numbers in the sequence\n",
    "if image_numbers:\n",
    "    min_number = min(image_numbers)\n",
    "    max_number = max(image_numbers)\n",
    "    full_range = set(range(min_number, max_number + 1))\n",
    "    existing_numbers = set(image_numbers)\n",
    "    missing_numbers = sorted(full_range - existing_numbers)\n",
    "else:\n",
    "    missing_numbers = []\n",
    "\n",
    "# Output results\n",
    "print(f\"Total images found: {len(image_numbers)}\")\n",
    "print(f\"Range of numbers: {min(image_numbers)} to {max(image_numbers)}\")\n",
    "print(f\"Missing numbers: {missing_numbers if missing_numbers else 'None'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c07e325e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images sorted from min to max and copied to: C:\\Users\\chara\\Downloads\\Assignment\\Licplatesdetection_train2_sorted\n"
     ]
    }
   ],
   "source": [
    "#train_preprocessing2\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Path to the original folder containing images\n",
    "image_folder = r\"C:\\Users\\chara\\Downloads\\Assignment\\Licplatesrecognition_train2\"\n",
    "\n",
    "# Path to the new folder for sorted images\n",
    "sorted_folder = r\"C:\\Users\\chara\\Downloads\\Assignment\\Licplatesdetection_train2_sorted\"\n",
    "\n",
    "# Step 1: Create the sorted folder if it doesn't exist\n",
    "os.makedirs(sorted_folder, exist_ok=True)\n",
    "\n",
    "# Step 2: List all files in the directory\n",
    "image_files = os.listdir(image_folder)\n",
    "\n",
    "# Step 3: Filter only valid image files (optional, based on your folder's contents)\n",
    "image_files = [f for f in image_files if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "# Step 4: Extract numeric parts of file names and sort them\n",
    "def extract_numeric(file_name):\n",
    "    \"\"\"Extracts numeric value from file name.\"\"\"\n",
    "    base_name = os.path.splitext(file_name)[0]\n",
    "    try:\n",
    "        return int(base_name)\n",
    "    except ValueError:\n",
    "        return float('inf')  # Push non-numeric names to the end if any\n",
    "\n",
    "sorted_files = sorted(image_files, key=extract_numeric)\n",
    "\n",
    "# Step 5: Copy files to the new folder in ascending order\n",
    "for idx, file_name in enumerate(sorted_files, start=1):\n",
    "    old_path = os.path.join(image_folder, file_name)\n",
    "    new_name = f\"{idx:03d}{os.path.splitext(file_name)[1]}\"  # Rename to 001.jpg, 002.jpg, etc.\n",
    "    new_path = os.path.join(sorted_folder, new_name)\n",
    "    shutil.copy2(old_path, new_path)\n",
    "\n",
    "print(f\"Images sorted from min to max and copied to: {sorted_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7fd7dac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images found: 900\n",
      "Range of numbers: 1 to 900\n",
      "Missing numbers: None\n"
     ]
    }
   ],
   "source": [
    "#train_preprocessing2\n",
    "\n",
    "import os\n",
    "\n",
    "# Path to the folder containing images\n",
    "image_folder = r\"C:\\Users\\chara\\Downloads\\Assignment\\Licplatesdetection_train2_sorted\"\n",
    "\n",
    "# Step 1: List all files in the directory\n",
    "image_files = os.listdir(image_folder)\n",
    "\n",
    "# Step 2: Filter only valid image files\n",
    "image_files = [f for f in image_files if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "# Step 3: Extract numeric parts of file names\n",
    "def extract_numeric(file_name):\n",
    "    \"\"\"Extracts numeric value from file name.\"\"\"\n",
    "    base_name = os.path.splitext(file_name)[0]\n",
    "    try:\n",
    "        return int(base_name)\n",
    "    except ValueError:\n",
    "        return None  # Ignore files without numeric names\n",
    "\n",
    "image_numbers = [extract_numeric(f) for f in image_files]\n",
    "image_numbers = [num for num in image_numbers if num is not None]  # Remove None values\n",
    "\n",
    "# Step 4: Find missing numbers in the sequence\n",
    "if image_numbers:\n",
    "    min_number = min(image_numbers)\n",
    "    max_number = max(image_numbers)\n",
    "    full_range = set(range(min_number, max_number + 1))\n",
    "    existing_numbers = set(image_numbers)\n",
    "    missing_numbers = sorted(full_range - existing_numbers)\n",
    "else:\n",
    "    missing_numbers = []\n",
    "\n",
    "# Output results\n",
    "print(f\"Total images found: {len(image_numbers)}\")\n",
    "print(f\"Range of numbers: {min(image_numbers)} to {max(image_numbers)}\")\n",
    "print(f\"Missing numbers: {missing_numbers if missing_numbers else 'None'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "43ea13fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images sorted from min to max and copied to: C:\\Users\\chara\\Downloads\\Assignment\\test_sorted\n"
     ]
    }
   ],
   "source": [
    "#test_preprocessing\n",
    "\n",
    "#train_preprocessing2\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Path to the original folder containing images\n",
    "image_folder = r\"C:\\Users\\chara\\Downloads\\Assignment\\test\"\n",
    "\n",
    "# Path to the new folder for sorted images\n",
    "sorted_folder = r\"C:\\Users\\chara\\Downloads\\Assignment\\test_sorted\"\n",
    "\n",
    "# Step 1: Create the sorted folder if it doesn't exist\n",
    "os.makedirs(sorted_folder, exist_ok=True)\n",
    "\n",
    "# Step 2: List all files in the directory\n",
    "image_files = os.listdir(image_folder)\n",
    "\n",
    "# Step 3: Filter only valid image files (optional, based on your folder's contents)\n",
    "image_files = [f for f in image_files if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "# Step 4: Extract numeric parts of file names and sort them\n",
    "def extract_numeric(file_name):\n",
    "    \"\"\"Extracts numeric value from file name.\"\"\"\n",
    "    base_name = os.path.splitext(file_name)[0]\n",
    "    try:\n",
    "        return int(base_name)\n",
    "    except ValueError:\n",
    "        return float('inf')  # Push non-numeric names to the end if any\n",
    "\n",
    "sorted_files = sorted(image_files, key=extract_numeric)\n",
    "\n",
    "# Step 5: Copy files to the new folder in ascending order\n",
    "for idx, file_name in enumerate(sorted_files, start=1):\n",
    "    old_path = os.path.join(image_folder, file_name)\n",
    "    new_name = f\"{idx:03d}{os.path.splitext(file_name)[1]}\"  # Rename to 001.jpg, 002.jpg, etc.\n",
    "    new_path = os.path.join(sorted_folder, new_name)\n",
    "    shutil.copy2(old_path, new_path)\n",
    "\n",
    "print(f\"Images sorted from min to max and copied to: {sorted_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8bdb3363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images found: 210\n",
      "Range of numbers: 1 to 210\n",
      "Missing numbers: None\n"
     ]
    }
   ],
   "source": [
    "#train_preprocessing2\n",
    "\n",
    "import os\n",
    "\n",
    "# Path to the folder containing images\n",
    "image_folder = r\"C:\\Users\\chara\\Downloads\\Assignment\\test_sorted\"\n",
    "\n",
    "# Step 1: List all files in the directory\n",
    "image_files = os.listdir(image_folder)\n",
    "\n",
    "# Step 2: Filter only valid image files\n",
    "image_files = [f for f in image_files if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "# Step 3: Extract numeric parts of file names\n",
    "def extract_numeric(file_name):\n",
    "    \"\"\"Extracts numeric value from file name.\"\"\"\n",
    "    base_name = os.path.splitext(file_name)[0]\n",
    "    try:\n",
    "        return int(base_name)\n",
    "    except ValueError:\n",
    "        return None  # Ignore files without numeric names\n",
    "\n",
    "image_numbers = [extract_numeric(f) for f in image_files]\n",
    "image_numbers = [num for num in image_numbers if num is not None]  # Remove None values\n",
    "\n",
    "# Step 4: Find missing numbers in the sequence\n",
    "if image_numbers:\n",
    "    min_number = min(image_numbers)\n",
    "    max_number = max(image_numbers)\n",
    "    full_range = set(range(min_number, max_number + 1))\n",
    "    existing_numbers = set(image_numbers)\n",
    "    missing_numbers = sorted(full_range - existing_numbers)\n",
    "else:\n",
    "    missing_numbers = []\n",
    "\n",
    "# Output results\n",
    "print(f\"Total images found: {len(image_numbers)}\")\n",
    "print(f\"Range of numbers: {min(image_numbers)} to {max(image_numbers)}\")\n",
    "print(f\"Missing numbers: {missing_numbers if missing_numbers else 'None'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1b7bfdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Dataset Paths\n",
    "TRAIN1_PATH = r\"C:\\Users\\chara\\Downloads\\Assignment\\Licplatesdetection_train1_sorted\"  # Vehicle images with bounding box annotations\n",
    "TRAIN1_ANNOTATIONS = r\"C:\\Users\\chara\\Downloads\\Assignment\\Licplatesdetection_train1_sorted_annotations.csv\"  # Annotations for Training Set 1\n",
    "\n",
    "TRAIN2_PATH = r\"C:\\Users\\chara\\Downloads\\Assignment\\Licplatesdetection_train2_sorted\"  # License plate images with text annotations\n",
    "TRAIN2_ANNOTATIONS = r\"C:\\Users\\chara\\Downloads\\Assignment\\Licplatesdetection_train2_sorted_annotations_updated.csv\"  # Text annotations for Training Set 2\n",
    "\n",
    "TEST_PATH = r\"C:\\Users\\chara\\Downloads\\Assignment\\test_sorted\" # Test set images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bbcd9a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 900\n",
      "Missing image numbers: [15, 269, 383, 420, 439, 467, 538, 556, 568, 734, 909]\n",
      "Repeated image numbers: []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(900, [15, 269, 383, 420, 439, 467, 538, 556, 568, 734, 909], [])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def analyze_images(folder_path):\n",
    "    # Define valid image extensions\n",
    "    image_extensions = ('.png', '.jpg', '.jpeg')\n",
    "\n",
    "    # Get all image filenames in the folder\n",
    "    image_files = [\n",
    "        file for file in os.listdir(folder_path)\n",
    "        if file.lower().endswith(image_extensions)\n",
    "    ]\n",
    "\n",
    "    # Extract numeric parts of filenames (if they are numbers)\n",
    "    image_numbers = [\n",
    "        int(os.path.splitext(file)[0]) for file in image_files if file.split('.')[0].isdigit()\n",
    "    ]\n",
    "\n",
    "    # Sort the numbers for analysis\n",
    "    image_numbers.sort()\n",
    "\n",
    "    # Total number of images\n",
    "    total_images = len(image_numbers)\n",
    "\n",
    "    # Find missing numbers in the range\n",
    "    if image_numbers:\n",
    "        full_range = set(range(min(image_numbers), max(image_numbers) + 1))\n",
    "        missing_numbers = sorted(full_range - set(image_numbers))\n",
    "    else:\n",
    "        missing_numbers = []\n",
    "\n",
    "    # Find repeated numbers\n",
    "    repeated_numbers = sorted([num for num in set(image_numbers) if image_numbers.count(num) > 1])\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Total images: {total_images}\")\n",
    "    print(f\"Missing image numbers: {missing_numbers}\")\n",
    "    print(f\"Repeated image numbers: {repeated_numbers}\")\n",
    "\n",
    "    return total_images, missing_numbers, repeated_numbers\n",
    "\n",
    "# Example usage:\n",
    "folder_path = r\"C:\\Users\\chara\\Downloads\\licpr\\Licplatesrecognition_train2\"  # Replace with the path to your folder containing images\n",
    "analyze_images(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9c7a7ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset for Training Set 1\n",
    "class LicensePlateDataset(Dataset):\n",
    "    def __init__(self, image_dir, annotations_file, transform=None):\n",
    "        \"\"\"\n",
    "        image_dir: Directory containing the images.\n",
    "        annotations_file: CSV file with bounding box annotations.\n",
    "        transform: Data augmentation or transformations.\n",
    "        \"\"\"\n",
    "        self.image_dir = image_dir\n",
    "        self.annotations = pd.read_csv(annotations_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image and annotations\n",
    "        img_path = os.path.join(self.image_dir, self.annotations.iloc[idx, 0])\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        boxes = self.annotations.iloc[idx, 1:5].values.astype('float32').tolist()\n",
    "        labels = torch.ones((1,), dtype=torch.int64)  # Assuming single class (license plate)\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        target = {\n",
    "            \"boxes\": torch.tensor([boxes]),\n",
    "            \"labels\": labels,\n",
    "        }\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a5a03438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the License Plate Detection Model\n",
    "def build_detection_model():\n",
    "    \"\"\"\n",
    "    Creates a Faster R-CNN model pre-trained on the COCO dataset.\n",
    "    \"\"\"\n",
    "    model = fasterrcnn_resnet50_fpn(weights=\"COCO_V1\")  # Updated to use the correct parameter\n",
    "    # Modify the classifier to detect only one class (license plate)\n",
    "    num_classes = 2  # Background + License Plate\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = nn.Linear(in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "# Initialize the model\n",
    "detection_model = build_detection_model()\n",
    "detection_model = detection_model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "df0092f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset for Training Set 2 (License Plate OCR)\n",
    "class LicensePlateOCRDataset(Dataset):\n",
    "    def __init__(self, image_dir, annotations_file, transform=None):\n",
    "        \"\"\"\n",
    "        image_dir: Directory containing cropped license plate images.\n",
    "        annotations_file: CSV file with license plate text annotations.\n",
    "        transform: Data augmentation or transformations.\n",
    "        \"\"\"\n",
    "        self.image_dir = image_dir\n",
    "        self.annotations = pd.read_csv(annotations_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image and corresponding text\n",
    "        img_path = os.path.join(self.image_dir, self.annotations.iloc[idx, 0])\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        label = self.annotations.iloc[idx, 1]\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dfa69e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chara\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\chara\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Build OCR Model using Pre-trained ResNet\n",
    "class LicensePlateOCR(nn.Module):\n",
    "    def __init__(self, num_classes=36):  # 26 letters + 10 digits\n",
    "        super(LicensePlateOCR, self).__init__()\n",
    "        self.backbone = models.resnet18(pretrained=True)\n",
    "        self.backbone.fc = nn.Linear(self.backbone.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "# Initialize the OCR model\n",
    "ocr_model = LicensePlateOCR(num_classes=36)  # Adjust for alphanumeric output\n",
    "ocr_model = ocr_model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "23621d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function for Detection Model\n",
    "def train_detection_model(model, dataloader, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for images, targets in dataloader:\n",
    "            images = list(img.to('cpu') for img in images)\n",
    "            targets = [{k: v.to('cpu') for k, v in t.items()} for t in targets]\n",
    "\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += losses.item()\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "# Training Function for OCR Model\n",
    "def train_ocr_model(model, dataloader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to('cpu')\n",
    "            labels = labels.to('cpu')\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3bb8f333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Inference Pipeline with Results Storage\n",
    "def detect_and_recognize(image_paths, detection_model, ocr_model, output_excel_path):\n",
    "    \"\"\"\n",
    "    Processes a list of image paths, detects license plates, recognizes characters, \n",
    "    and saves results in an Excel file.\n",
    "\n",
    "    image_paths: List of paths to test images.\n",
    "    detection_model: Pre-trained license plate detection model.\n",
    "    ocr_model: Pre-trained OCR model.\n",
    "    output_excel_path: Path to save the Excel file.\n",
    "    \"\"\"\n",
    "    results = []  # To store results in a list\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        # Read the image\n",
    "        image = cv2.imread(image_path)\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        transform = transforms.ToTensor()\n",
    "        image_tensor = transform(image_rgb).unsqueeze(0).to('cpu')\n",
    "\n",
    "        # Step 1: Detect License Plate\n",
    "        detection_model.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions = detection_model(image_tensor)\n",
    "\n",
    "        # Extract bounding box if available\n",
    "        if len(predictions[0]['boxes']) > 0:\n",
    "            box = predictions[0]['boxes'][0].cpu().numpy().astype(int)\n",
    "            cropped = image_rgb[box[1]:box[3], box[0]:box[2]]\n",
    "\n",
    "            # Step 2: OCR Recognition\n",
    "            ocr_model.eval()\n",
    "            transform = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor()\n",
    "            ])\n",
    "            cropped_tensor = transform(cropped).unsqueeze(0).to('cpu')\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = ocr_model(cropped_tensor)\n",
    "                predicted_text = \"\".join(chr(c + ord('A')) for c in output.argmax(dim=1).cpu().numpy())\n",
    "        else:\n",
    "            predicted_text = \"License plate not detected\"\n",
    "\n",
    "        # Append the result (image name and detected text)\n",
    "        results.append({\n",
    "            \"Image Name\": os.path.basename(image_path),\n",
    "            \"Detected Text\": predicted_text\n",
    "        })\n",
    "\n",
    "    # Convert results to a DataFrame and save as Excel\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results.to_excel(output_excel_path, index=False)\n",
    "    print(f\"Results saved to {output_excel_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "423b1552",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[107], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m output_excel_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlicense_plate_results.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Run the pipeline\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m detect_and_recognize(test_image_paths, detection_model, ocr_model, output_excel_path)\n",
      "Cell \u001b[1;32mIn[106], line 26\u001b[0m, in \u001b[0;36mdetect_and_recognize\u001b[1;34m(image_paths, detection_model, ocr_model, output_excel_path)\u001b[0m\n\u001b[0;32m     24\u001b[0m detection_model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 26\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m detection_model(image_tensor)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Extract bounding box if available\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(predictions[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboxes\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\detection\\generalized_rcnn.py:105\u001b[0m, in \u001b[0;36mGeneralizedRCNN.forward\u001b[1;34m(self, images, targets)\u001b[0m\n\u001b[0;32m    103\u001b[0m     features \u001b[38;5;241m=\u001b[39m OrderedDict([(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m, features)])\n\u001b[0;32m    104\u001b[0m proposals, proposal_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrpn(images, features, targets)\n\u001b[1;32m--> 105\u001b[0m detections, detector_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroi_heads(features, proposals, images\u001b[38;5;241m.\u001b[39mimage_sizes, targets)\n\u001b[0;32m    106\u001b[0m detections \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m.\u001b[39mpostprocess(detections, images\u001b[38;5;241m.\u001b[39mimage_sizes, original_image_sizes)  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n\u001b[0;32m    108\u001b[0m losses \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\detection\\roi_heads.py:763\u001b[0m, in \u001b[0;36mRoIHeads.forward\u001b[1;34m(self, features, proposals, image_shapes, targets)\u001b[0m\n\u001b[0;32m    761\u001b[0m box_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbox_roi_pool(features, proposals, image_shapes)\n\u001b[0;32m    762\u001b[0m box_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbox_head(box_features)\n\u001b[1;32m--> 763\u001b[0m class_logits, box_regression \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbox_predictor(box_features)\n\u001b[0;32m    765\u001b[0m result: List[Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    766\u001b[0m losses \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# List of test image paths\n",
    "test_image_paths = [os.path.join(TEST_PATH, img) for img in os.listdir(TEST_PATH) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "# Path to save the Excel file\n",
    "output_excel_path = \"license_plate_results.xlsx\"\n",
    "\n",
    "# Run the pipeline\n",
    "detect_and_recognize(test_image_paths, detection_model, ocr_model, output_excel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d4165e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: C:\\Users\\chara\\Downloads\\Assignment\\Licplatesdetection_train1_sorted_annotations.csv does not contain the required columns\n",
      "Error: C:\\Users\\chara\\Downloads\\Assignment\\Licplatesdetection_train2_sorted_annotations_updated.csv does not contain the required columns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def verify_detection_dataset(image_dir, annotations_file):\n",
    "    try:\n",
    "        annotations = pd.read_csv(annotations_file)\n",
    "        required_columns = [\"filename\", \"xmin\", \"ymin\", \"xmax\", \"ymax\"]\n",
    "        if not all(col in annotations.columns for col in required_columns):\n",
    "            print(f\"Error: {annotations_file} does not contain the required columns\")\n",
    "            return False\n",
    "        \n",
    "        for idx, row in annotations.iterrows():\n",
    "            img_path = os.path.join(image_dir, row['filename'])\n",
    "            if not os.path.exists(img_path):\n",
    "                print(f\"Error: Image file {img_path} does not exist\")\n",
    "                return False\n",
    "        \n",
    "        print(f\"Detection dataset in {annotations_file} is correctly formatted and all files exist\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {annotations_file}: {e}\")\n",
    "        return False\n",
    "\n",
    "def verify_ocr_dataset(image_dir, annotations_file):\n",
    "    try:\n",
    "        annotations = pd.read_csv(annotations_file)\n",
    "        required_columns = [\"filename\", \"text\"]\n",
    "        if not all(col in annotations.columns for col in required_columns):\n",
    "            print(f\"Error: {annotations_file} does not contain the required columns\")\n",
    "            return False\n",
    "        \n",
    "        for idx, row in annotations.iterrows():\n",
    "            img_path = os.path.join(image_dir, row['filename'])\n",
    "            if not os.path.exists(img_path):\n",
    "                print(f\"Error: Image file {img_path} does not exist\")\n",
    "                return False\n",
    "        \n",
    "        print(f\"OCR dataset in {annotations_file} is correctly formatted and all files exist\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {annotations_file}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Verify the datasets\n",
    "verify_detection_dataset(TRAIN1_PATH, TRAIN1_ANNOTATIONS)\n",
    "verify_ocr_dataset(TRAIN2_PATH, TRAIN2_ANNOTATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bb2d35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
